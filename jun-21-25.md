# summary of what i did today

- install docker engine in my ubuntu
- ~~add iptables policies that prevent unauthorized access to containers or other services running on your host~~
- decide to create custom bridge instead to prevent outside access to container
- no need to add user to docker group since we can just use sudo to get access to unix socket
- installing node

## add iptables policies to prevent unauth access to containers on my host

this is like cascade, so we have to write it before docker's to make it take precedence

this is the reference at the time of writing this

https://docs.docker.com/engine/network/packet-filtering-firewalls/#add-iptables-policies-before-dockers-rules

do not use the forward chain, use docker user chain

because forward is too late, we have to get packages before docker does

the way docker works is that it maps virtual container port to host port
so at the time you reach docker-user chain, the mapping was already done
so if you target the container virtual port say 8080, its not there anymore at the docker-user chain since it has been mapped to maybe host 80
so we have to use conntrack to be able to work with host


say packet comes in from outside, someone uses client browser to go to port 80
so from pub ip 80, docker maps that to internal docker virtual ip and port
this happens before docker-user chain
this means by the time we work using docker-user, 80 is not valid no more, the valid one is 8080 port and 172.17.0.2 ip virtual container
so we want a way where we can work this way in docker-user chain
even if it targets host ip and port originally and NOW its rewritten to somewhere else the docker virtual port and ip, consider it!
but by default it would ignore that
to make it consider it we use conntrack
this way we can work using the real port and ip as base of reference, not container virtual values

```bash
sudo iptables -I DOCKER-USER -p tcp -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT
sudo iptables -I DOCKER-USER -p tcp -m conntrack --ctorigdst 198.51.100.2 --ctorigdstport 80 -j ACCEPT
```

notice that 198.51.100.2 and 80, we were able to work in real host values

---

know that the way docker works is that
it maps virtual port to host port
so if virtual docker port at 80, can be mapped to be exposed to the world at any real port like 8080
it does that using
iptables
NAT
PAT
masquerading
docker run -p 8080:80 [...]
that means
we want 80 to masquerade as real 8080 on host port

---

this is how to restrict external connection to containers

by default
external source IP
can connect to containers that are published on host port

to allow certain ip to access container
on docker user chain
insert rule
this drop packets from all ip except 192.0.2.2

```bash
iptables -I DOCKER-USER -i ext_if ! -s 192.0.2.2 -j DROP
```

You will need to change ext_if to correspond with your host's actual external interface

there are other ways to filter, by subnet or ip range

---

after reading

I have found out that the doc provides strategies to avoid exposing container to the internet

and there are 2 ways of doing this either you edit the iptable rules

or you make your own custom bridge

here are the refs that talks about making iptable rules
- https://github.com/chaifeng/ufw-docker?tab=readme-ov-file#solving-ufw-and-docker-issues
- https://github.com/moby/moby/issues/4737#issuecomment-419705925

this official docker doc also has ways to make uptable rules but it also have the method to make your own bridge
- https://docs.docker.com/engine/network/packet-filtering-firewalls/#setting-the-default-bind-address-for-containers

i have decided to use the bridge, so that
- local postgres is SAFE against internet
- any user wanting to start this app LOCALLY is confident that the docker dbms is safe from outside world

to do that i just have to add this to the docker compose yaml, that is the thing that is responsible for making the custom bridge

here is a quick example

```yaml
networks:
  mysecurebridge:
    driver: bridge
    driver_opts:
      com.docker.network.bridge.host_binding_ipv4: "127.0.0.1"

services:
  postgres:
    image: postgres
    ports:
      - "5432:5432"
    networks:
      - mysecurebridge
```

or maybe you also can programmatically make it via bash, can also destroy it on cleaup

```bash
echo "üîç Checking if 'mysecurebridge' network exists..."
if ! docker network ls --format '{{.Name}}' | grep -Fxq "mysecurebridge"; then
    echo "üì° Creating 'mysecurebridge' network bound to 127.0.0.1..."
    docker network create \
        --driver bridge \
        -o "com.docker.network.bridge.host_binding_ipv4=127.0.0.1" \
        mysecurebridge
fi
```

user that are not familiar with this wont be disturbed at all
just run and use
custom bridge protects them from outside access by default
custom bridge name is also name spaced so no need to check or alert them for name collision

---

installing docker since i have read the firewall issue

to install docker i have to ensure i have prereq

first one is this

OS requirements

To install Docker Engine, you need the 64-bit version of one of these Ubuntu versions:

    Ubuntu Oracular 24.10
    Ubuntu Noble 24.04 (LTS)
    Ubuntu Jammy 22.04 (LTS)

Docker Engine for Ubuntu is compatible with x86_64 (or amd64), armhf, arm64, s390x, and ppc64le (ppc64el) architectures.

Note

Installation on Ubuntu derivative distributions, such as Linux Mint, is not officially supported (though it may work).

i have 64 bit arch
```bash
uname -m
# this gives back machine name
x86_64
```

then gotta check my ubuntu version
```bash
lsb_release -a

No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 24.04.2 LTS
Release:	24.04
Codename:	noble
```

so i am using one of the supported version
Ubuntu Noble 24.04 (LTS)

- [x] 64-bit
- [x] one of these Ubuntu versions (Ubuntu Noble 24.04 (LTS))
- [x] Docker Engine for Ubuntu is compatible with x86_64 (or amd64)

then...

gotta uninstall old versions

Your Linux distribution may provide unofficial Docker packages, which may conflict with the official packages provided by Docker. You must uninstall these packages before you install the official version of Docker Engine.

The unofficial packages to uninstall are:

    docker.io
    docker-compose
    docker-compose-v2
    docker-doc
    podman-docker
    
Moreover, Docker Engine depends on containerd and runc. Docker Engine bundles these dependencies as one bundle: containerd.io. If you have installed the containerd or runc previously, uninstall them to avoid conflicts

Run the following command to uninstall all conflicting packages:
```bash
for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done
```
that above is all from the doc copy pasted at time of writing

Images, containers, volumes, and networks stored in /var/lib/docker/ aren't automatically removed when you uninstall Docker. If you want to start with a clean installation, and prefer to clean up any existing data, read the uninstall Docker Engine section.

So I should do clean uninstallation too

Uninstall Docker Engine

    Uninstall the Docker Engine, CLI, containerd, and Docker Compose packages:

 sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin docker-ce-rootless-extras

Images, containers, volumes, or custom configuration files on your host aren't automatically removed. To delete all images, containers, and volumes:

 sudo rm -rf /var/lib/docker

 sudo rm -rf /var/lib/containerd

Remove source list and keyrings

 sudo rm /etc/apt/sources.list.d/docker.list

     sudo rm /etc/apt/keyrings/docker.asc

You have to delete any edited configuration files manually.

all above are from doc

so basically i have to ensure that i start at clean slate
because if for whatever reason my ubuntu comes with an old docker
conflicts may happen
so have to nuke any docker if it exists right now with this
```bash
for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done

sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin docker-ce-rootless-extras

sudo rm -rf /var/lib/docker
sudo rm -rf /var/lib/containerd

sudo rm /etc/apt/sources.list.d/docker.list
sudo rm /etc/apt/keyrings/docker.asc
```

ok finally

time to install

there are different ways of installation

Installation methods

You can install Docker Engine in different ways, depending on your needs:

    Docker Engine comes bundled with Docker Desktop for Linux. This is the easiest and quickest way to get started.

    Set up and install Docker Engine from Docker's apt repository.

    Install it manually and manage upgrades manually.

    Use a convenience script. Only recommended for testing and development environments.
    


I am going to use the `Docker Engine via apt`
- native ubuntu package manager
- actively supported
- easy apt update + auto update from the software updater gui notif


this is from the doc again
since I am installing it for the first time, I have to set the docker apt repo

Install using the apt repository

Before you install Docker Engine for the first time on a new host machine, you need to set up the Docker apt repository. Afterward, you can install and update Docker from the repository.

setup docker apt repo
```bash
# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
```

install docker packages
```bash
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```

test successful install by running their hello world image
```bash
sudo docker run hello-world
```
if it all goes well then i have gotten docker successfully

i got success hello world

notice it uses sudo, this is because it edits iptable, but you can add urself to the docker user group

todo, read this to add urself to user group, linux postinstall
this allow non root to use docker
https://docs.docker.com/engine/install/linux-postinstall/

---

docker install creates the docker user group

you want to add yourself to that group, cuz if not u have to use sudo to run docker
to do that
i have to follow this linux postinstall
https://docs.docker.com/engine/install/linux-postinstall
this allow non root, me, to run docker without sudo

Linux post-installation steps for Docker Engine
configure your Linux host machine to work better with Docker

Manage Docker as a non-root user
When we say "The Docker daemon binds to a Unix socket, not a TCP port", it means:
Docker communicates over a special file on your system, not over the network by default.

Unix Socket (/var/run/docker.sock)
A file-based interface for inter-process communication (IPC).
Located at: /var/run/docker.sock.
Only accessible locally (on the same machine).
Used by Docker clients (like the CLI) to talk to the Docker daemon.
Unix socket is like a private direct phone line between programs on the same machine.

Security: Only local users with permission can access it.
Performance: Slightly faster due to no network stack involved.

```json
docker ps
```
sends an HTTP request over that socket to the Docker daemon
/var/run/docker.sock

If you want to access Docker remotely (e.g., from another machine), then you configure Docker to also listen on a TCP port, like this in /etc/docker/daemon.json:
```json
{
  "hosts": ["unix:///var/run/docker.sock", "tcp://127.0.0.1:2375"]
}
```
But this is not recommended unless secured with TLS or limited to localhost.

so by default it uses local file based routing over http protocol, not network based over network interface eth0
this kind of file local communication is called 'Unix socket'

By default it's the root user that owns the Unix socket, and other users can only access it using sudo. The Docker daemon always runs as the root user.
when we say `runs as root`
we mean
process is owned by the root user and has root-level privileges
or
In Linux, commands (or more precisely, processes) run as a specific user, which determines what permissions they have ‚Äî similar to a role in RBAC.

So when we say:

    "Command X runs as root"

We mean:

    "The process started by this command runs with the full privileges of the root user (UID 0)"

And therefore:

    "You must be root (or use sudo) to run it"
    
Each user acts like a role
A command takes on the permissions of the user who runs it

since docker needs to use the unix socket, which by default is owned by root, thus you give it permission with sudo

after thinking about it, not adding yourself to docker group is better for security reason
do not want other user to expose their docker access to non root and later blame it on me if things go bad
so
just sudo it

---

installing nodejs

up to you to do this since the ubuntu gui does it for you when the notification pops up from the software updater anyways
maybe good to do this first before installing new things
Updates the package manager‚Äôs view of available packages
Upgrades your currently installed packages to the latest versions
```bash
sudo apt update && sudo apt upgrade
```

here is the site
https://nodejs.org/en/download

from odin
sudo apt install curl
sudo apt update && sudo apt upgrade
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.1/install.sh | bash
export NVM_DIR="$([ -z "${XDG_CONFIG_HOME-}" ] && printf %s "${HOME}/.nvm" || printf %s "${XDG_CONFIG_HOME}/nvm")"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" # This loads nvm
command -v nvm
nvm install --lts
nvm use --lts

lets just see what both offers from odin and the original node site
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.1/install.sh | bash
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.3/install.sh | bash  <--- this one from official site has newer bash installer

odin has this though
export NVM_DIR="$([ -z "${XDG_CONFIG_HOME-}" ] && printf %s "${HOME}/.nvm" || printf %s "${XDG_CONFIG_HOME}/nvm")"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh" # This loads nvm
which
sets the nvm dir env var
depending if u have xdg, then it uses that
else
it uses the home/.nvm

then it just sources nvm.sh to current shell session

...

whatever lets just run the latest bash they have
```bash
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.3/install.sh | bash
```

this is the output
=> Downloading nvm from git to '/home/asd/.nvm'             <------------- this is where nvm is /home/urusername/.nvm, it git clone and dump the nvm repo there
=> Cloning into '/home/asd/.nvm'...                         <------------- in nvm repo, there is the nvm.sh that loads nvm software, bash_completion for tab autocomplete, .git is the repo
remote: Enumerating objects: 382, done.
remote: Counting objects: 100% (382/382), done.
remote: Compressing objects: 100% (325/325), done.
remote: Total 382 (delta 43), reused 178 (delta 29), pack-reused 0 (from 0)
Receiving objects: 100% (382/382), 385.06 KiB | 306.00 KiB/s, done.
Resolving deltas: 100% (43/43), done.
* (HEAD detached at FETCH_HEAD)
  master
=> Compressing and cleaning up git repository

=> Appending nvm source string to /home/asd/.bashrc                     <------------ ~/.bashrc = bash startup script = AKA ran everytime u open a bash term emu, for env vars setups
=> Appending bash_completion source string to /home/asd/.bashrc         <------------ this adds nvm and autocompletion to be ready whenever u summon a bash term emu
=> Close and reopen your terminal to start using nvm or run the following to use it now:

export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm
[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"  # This loads nvm bash_completion

notice that when you enter bashrc you see that it sets this up, so that on every terminal session it points to the repo in home
```bash
export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm
[ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"  # This loads nvm bash_completion
```

long story short, i use curl to ran that bash that nvm have to do the following
Which means that now i have a repo nvm at home
bashrc append that var pointer to that repo on every term emu i make

i can move this repo to
~/.config/nvm

which might be a good thing if i want to
- not clutter home
- 1 dir that holds all config stuff that lets me
    - backup
    - put on cloud
    - just pull it and there it is

but maybe who cares, if it works it works
if i am in new machine
then just set the whole thing up again as if its the first time

btw bashrc is just like any other bash script
so say u update it
then just manually run it again
voila u get ur setup ran again, in case u edit it or whatever

ok now that we have nvm
have to use it to get node, its the 'Node Version Manager' after all
the thing that manages node

the official site does this

# Download and install Node.js:
nvm install 22

# Verify the Node.js version:
node -v # Should print "v22.16.0".
nvm current # Should print "v22.16.0".

# Verify npm version:
npm -v # Should print "10.9.2".

but i probably want the lts, 22 is new at the time of writing so id rather use stable one

nvm install --lts
nvm use --lts

this comes with
- nvm = the node version manager, use this to update node and stuff
- node = compiles js to machine code
- npm = interface to load in code from artifact repo from js community

btw no need to call the nvm use
u wanna call nvm use to switch version for the current session
a repo should probably have .nvmrc at root
so when user go to root and do nvm use
whatever is in .nvmrc, their nvm will use it

anyways
nvm use
is scoped in current session

ok so basically
when I use nvm to get node version
i can set hey this is my default ok, say the alias lts
so that whenever I summon term emu i get lts
but I have the freedom to switch in any currently scoped emu term session to other versions with nvm use

btw calling nvm install also auto sets alias for default node version

nvm install --lts
Installing latest LTS version.
Downloading and installing node v22.16.0...
Downloading https://nodejs.org/dist/v22.16.0/node-v22.16.0-linux-x64.tar.xz...
################################################################################################################################################################################# 100.0%
Computing checksum with sha256sum
Checksums matched!
Now using node v22.16.0 (npm v10.9.2)
Creating default alias: default -> lts/* (-> v22.16.0)

whenever u get new node version, this thing auto sets the alias to point to that new node version u just installed
